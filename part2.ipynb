{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial Average\n",
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "from tqdm import tqdm\n",
    "from scipy.special import erf\n",
    "import pickle\n",
    "import itertools\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "\n",
    "# Personal libraries\n",
    "import henon_map as hm\n",
    "\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Radial average:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A/home/carlidel/Insync/carlo.montanari3@studio.unibo.it/OneDrive Biz/optimized_code/henon_map/henon_map/cpu_henon_core.py:148: RuntimeWarning: invalid value encountered in true_divide\n",
      "  matrices = np.nansum(matrices.reshape(\n",
      "\n",
      "  5%|▌         | 1/20 [00:05<01:52,  5.94s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:07<01:21,  4.52s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:08<00:59,  3.50s/it]\u001b[A\n",
      " 20%|██        | 4/20 [00:09<00:44,  2.79s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [00:10<00:34,  2.29s/it]\u001b[A\n",
      " 30%|███       | 6/20 [00:11<00:26,  1.93s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [00:12<00:21,  1.68s/it]\u001b[A\n",
      " 40%|████      | 8/20 [00:13<00:17,  1.49s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [00:14<00:14,  1.35s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [00:15<00:12,  1.24s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [00:16<00:10,  1.17s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [00:17<00:08,  1.10s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [00:18<00:07,  1.05s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [00:19<00:06,  1.01s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [00:20<00:04,  1.02it/s]\u001b[A\n",
      " 80%|████████  | 16/20 [00:21<00:03,  1.06it/s]\u001b[A\n",
      " 85%|████████▌ | 17/20 [00:22<00:02,  1.09it/s]\u001b[A\n",
      " 90%|█████████ | 18/20 [00:22<00:01,  1.13it/s]\u001b[A\n",
      " 95%|█████████▌| 19/20 [00:23<00:00,  1.18it/s]\u001b[A\n",
      "100%|██████████| 20/20 [00:24<00:00,  1.23s/it]\u001b[A\n",
      "Radial average: 100%|██████████| 1/1 [00:26<00:00, 26.08s/it]\n"
     ]
    }
   ],
   "source": [
    "error_2 = {}\n",
    "DA_2 = {}\n",
    "error_5 = {}\n",
    "DA_5 = {}\n",
    "count_matrix_2 = {}\n",
    "average_matrix_2 = {}\n",
    "raw_error_2 = {}\n",
    "\n",
    "alpha_preliminary_values = np.linspace(-1.0, 1.0, samples)\n",
    "alpha_values = np.arccos(alpha_preliminary_values) / 2\n",
    "d_preliminar_alpha = alpha_preliminary_values[1] - alpha_preliminary_values[0]\n",
    "\n",
    "for epsilon in tqdm(epsilons, desc=\"Radial average\"):\n",
    "    # Extracting the radiuses with theta1 = theta2 = 0.0\n",
    "    \n",
    "    engine = hm.radial_scan.generate_instance(\n",
    "        d_r, \n",
    "        alpha_values, \n",
    "        np.zeros(alpha_values.shape),\n",
    "        np.zeros(alpha_values.shape),\n",
    "        epsilon,\n",
    "        starting_position=starting_position\n",
    "    )\n",
    "    all_radiuses = engine.compute(turn_sampling)\n",
    "    \n",
    "    # Computing of the 2D values\n",
    "    \n",
    "    skips = [1]\n",
    "    while True:\n",
    "        if (alpha_max_samples - 1) // skips[-1] > 4:\n",
    "            skips.append(skips[-1] * 2)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    for i in skips:\n",
    "        alpha_prelim = alpha_preliminary_values[::i]\n",
    "        cutted_radiuses = all_radiuses[::i]\n",
    "        value = integrate.simps(cutted_radiuses ** 2, alpha_prelim, axis=0)\n",
    "        less_value = integrate.simps(cutted_radiuses[::2] ** 2, alpha_prelim[::2], axis=0)\n",
    "        uncertainty = np.abs((value - less_value))\n",
    "        \n",
    "        DA = np.sqrt(value / 2)\n",
    "        uncertainty = 0.5 * np.power(value / 2, -0.5) * uncertainty\n",
    "        DA_5[(epsilon, cutted_radiuses.shape)] = np.asarray(DA)\n",
    "        error_5[(epsilon, cutted_radiuses.shape)] = uncertainty \n",
    "    \n",
    "    # Rest of the Angular Averaging process\n",
    "    \n",
    "    values = []\n",
    "    for i in tqdm(range(len(turn_sampling))):\n",
    "        temp_values = np.array([[]])\n",
    "        for index, j in enumerate(range(0, samples, 128)):\n",
    "            stopping = (j + 128 if j != samples - 1 else samples)\n",
    "            radiuses = all_radiuses[j : stopping, i]\n",
    "\n",
    "            engine = hm.full_track.generate_instance(\n",
    "                radiuses,\n",
    "                alpha_values[j : stopping],\n",
    "                np.zeros(alpha_values.shape)[j : stopping],\n",
    "                np.zeros(alpha_values.shape)[j : stopping],\n",
    "                np.ones(alpha_values.shape, dtype=np.int)[j : stopping] * turn_sampling[i],\n",
    "                epsilon)\n",
    "\n",
    "            x, y, px, py = engine.compute()\n",
    "            \n",
    "            _ = engine.accumulate_and_return(n_subdivisions)\n",
    "            tmp_count_matrix = engine.count_matrix\n",
    "            tmp_avg_matrix = engine.matrices\n",
    "            if index == 0:\n",
    "                list_count_matrix = tmp_count_matrix\n",
    "                list_avg_matrix = tmp_avg_matrix\n",
    "            else:\n",
    "                list_count_matrix = np.concatenate((list_count_matrix, tmp_count_matrix))\n",
    "                list_avg_matrix = np.concatenate((list_avg_matrix, tmp_avg_matrix))\n",
    "        \n",
    "        count_total, matrix_total, result_total = hm.cpu_accumulate_and_return(list_count_matrix, list_avg_matrix)\n",
    "        \n",
    "        values.append(result_total)\n",
    "        count_matrix_2[(epsilon, samples, turn_sampling[i])] = count_total\n",
    "        average_matrix_2[(epsilon, samples, turn_sampling[i])] = matrix_total\n",
    "    \n",
    "    steps = [1]\n",
    "    while True:\n",
    "        if (values[0][0].shape[0] - 1) / steps[-1] > 4:\n",
    "            steps.append(steps[-1] * 2)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    for jump in steps:\n",
    "        for j in range(len(values[0])):\n",
    "            DA = []\n",
    "            error = []\n",
    "            DA_mc = []\n",
    "            raw_error_mc = []\n",
    "            error_mc = []\n",
    "            for i in range(len(turn_sampling)):\n",
    "                DA.append(np.power(integrate.simps(values[i][j][::jump], alpha_preliminary_values[::jump]) * 0.5, 1/4))\n",
    "                temp = np.power(integrate.simps(values[i][j][::jump * 2], alpha_preliminary_values[::jump * 2]) * 0.5, 1/4)\n",
    "                error.append(np.absolute(DA[-1] - temp))\n",
    "                \n",
    "                DA_mc.append(np.power(np.average(values[i][j][::jump]), 1/4))\n",
    "                raw_error_mc.append(np.std(values[i][j][::jump]))\n",
    "                error_mc.append(0.25 * np.power(DA_mc[-1], -3) * np.std(values[i][j][::jump]) / np.sqrt(np.size(values[i][j][::jump])))\n",
    "                \n",
    "            DA_2[(epsilon, len(values[i][j][::jump]), 2 ** (j), \"int\")] = DA\n",
    "            error_2[(epsilon, len(values[i][j][::jump]), 2 ** (j), \"int\")] = error\n",
    "            DA_2[(epsilon, len(values[i][j][::jump]), 2 ** (j), \"mc\")] = DA_mc\n",
    "            error_2[(epsilon, len(values[i][j][::jump]), 2 ** (j), \"mc\")] = error_mc\n",
    "            raw_error_2[(epsilon, len(values[i][j][::jump]), 2 ** (j), \"mc\")] = raw_error_mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"demofile.txt\"):\n",
    "  os.remove(\"demofile.txt\")with open(savepath + \"data/DA_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(DA_2, f, protocol=4)\n",
    "    \n",
    "with open(savepath + \"data/error_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(error_2, f, protocol=4)\n",
    "\n",
    "with open(savepath + \"data/raw_error_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(raw_error_2, f, protocol=4)    \n",
    "\n",
    "with open(savepath + \"data/count_matrix_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(count_matrix_2, f, protocol=4)\n",
    "    \n",
    "with open(savepath + \"data/avg_matrix_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(average_matrix_2, f, protocol=4)\n",
    "\n",
    "with open(savepath + \"data/DA_5.pkl\", 'wb') as f:\n",
    "    pickle.dump(DA_5, f, protocol=4)\n",
    "    \n",
    "with open(savepath + \"data/error_5.pkl\", 'wb') as f:\n",
    "    pickle.dump(error_5, f, protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
