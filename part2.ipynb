{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial Average\n",
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "from tqdm import tqdm\n",
    "from scipy.special import erf\n",
    "import pickle\n",
    "import itertools\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "\n",
    "# Personal libraries\n",
    "import henon_map as hm\n",
    "\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Radial average:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\u001b[A/home/carlidel/Insync/carlo.montanari3@studio.unibo.it/OneDrive Biz/optimized_code/henon_map/henon_map/cpu_henon_core.py:148: RuntimeWarning: invalid value encountered in true_divide\n",
      "  matrices = np.nansum(matrices.reshape(\n",
      "\n",
      "  0%|          | 1/500 [00:25<3:33:28, 25.67s/it]\u001b[A\n",
      "  0%|          | 2/500 [00:46<3:21:00, 24.22s/it]\u001b[A\n",
      "  1%|          | 3/500 [01:07<3:11:23, 23.11s/it]\u001b[A\n",
      "  1%|          | 4/500 [01:27<3:04:46, 22.35s/it]\u001b[A\n",
      "  1%|          | 5/500 [01:48<2:59:56, 21.81s/it]\u001b[A\n",
      "  1%|          | 6/500 [02:08<2:56:29, 21.44s/it]\u001b[A\n",
      "  1%|▏         | 7/500 [02:29<2:54:36, 21.25s/it]\u001b[A\n",
      "  2%|▏         | 8/500 [02:50<2:52:39, 21.06s/it]\u001b[A\n",
      "  2%|▏         | 9/500 [03:10<2:50:36, 20.85s/it]\u001b[A\n",
      "  2%|▏         | 10/500 [03:30<2:49:15, 20.73s/it]\u001b[A\n",
      "  2%|▏         | 11/500 [03:51<2:48:23, 20.66s/it]\u001b[A\n",
      "  2%|▏         | 12/500 [04:11<2:47:02, 20.54s/it]\u001b[A\n",
      "  3%|▎         | 13/500 [04:31<2:46:02, 20.46s/it]\u001b[A\n",
      "  3%|▎         | 14/500 [04:52<2:44:51, 20.35s/it]\u001b[A\n",
      "  3%|▎         | 15/500 [05:12<2:43:52, 20.27s/it]\u001b[A\n",
      "  3%|▎         | 16/500 [05:32<2:43:05, 20.22s/it]\u001b[A\n",
      "  3%|▎         | 17/500 [05:52<2:43:13, 20.28s/it]\u001b[A\n",
      "  4%|▎         | 18/500 [06:13<2:43:47, 20.39s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "error_2 = {}\n",
    "DA_2 = {}\n",
    "count_matrix_2 = {}\n",
    "average_matrix_2 = {}\n",
    "raw_error_2 = {}\n",
    "\n",
    "alpha_preliminary_values = np.linspace(-1.0, 1.0, samples)\n",
    "alpha_values = np.arccos(alpha_preliminary_values) / 2\n",
    "d_preliminar_alpha = alpha_preliminary_values[1] - alpha_preliminary_values[0]\n",
    "\n",
    "for epsilon in tqdm(epsilons, desc=\"Radial average\"):\n",
    "    # Extracting the radiuses with theta1 = theta2 = 0.0\n",
    "    \n",
    "    engine = hm.radial_scan.generate_instance(\n",
    "        d_r, \n",
    "        alpha_values, \n",
    "        np.zeros(alpha_values.shape),\n",
    "        np.zeros(alpha_values.shape),\n",
    "        epsilon,\n",
    "        starting_position=starting_position\n",
    "    )\n",
    "    all_radiuses = engine.compute(turn_sampling)\n",
    "    \n",
    "    # Computing of the 2D values\n",
    "    \n",
    "    skips = [1]\n",
    "    while True:\n",
    "        if (alpha_max_samples - 1) // skips[-1] > 4:\n",
    "            skips.append(skips[-1] * 2)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    for i in skips:\n",
    "        alpha = alpha_values[::i]\n",
    "        cutted_radiuses = all_radiuses[::i]\n",
    "        value = integrate.simps(cutted_radiuses ** 2, alpha, axis=0)\n",
    "        less_value = integrate.simps(cutted_radiuses[::2] ** 2, alpha[::2], axis=0)\n",
    "        uncertainty = np.abs((value - less_value))\n",
    "        \n",
    "        DA = np.sqrt(value * 2 / np.pi)\n",
    "        uncertainty = 0.5 * np.power(value * 2 / np.pi, -0.5) * uncertainty\n",
    "        DA_5[(epsilon, cutted_radiuses.shape)] = np.asarray(DA)\n",
    "        error_5[(epsilon, cutted_radiuses.shape)] = uncertainty \n",
    "    \n",
    "    # Rest of the Angular Averaging process\n",
    "    \n",
    "    values = []\n",
    "    for i in tqdm(range(len(turn_sampling))):\n",
    "        temp_values = np.array([[]])\n",
    "        for index, j in enumerate(range(0, samples, 128)):\n",
    "            stopping = (j + 128 if j != samples - 1 else samples)\n",
    "            radiuses = all_radiuses[j : stopping, i]\n",
    "\n",
    "            engine = hm.full_track.generate_instance(\n",
    "                radiuses,\n",
    "                alpha_values[j : stopping],\n",
    "                np.zeros(alpha_values.shape)[j : stopping],\n",
    "                np.zeros(alpha_values.shape)[j : stopping],\n",
    "                np.ones(alpha_values.shape, dtype=np.int)[j : stopping] * turn_sampling[i],\n",
    "                epsilon)\n",
    "\n",
    "            x, y, px, py = engine.compute()\n",
    "            \n",
    "            _ = engine.accumulate_and_return(n_subdivisions)\n",
    "            tmp_count_matrix = engine.count_matrix\n",
    "            tmp_avg_matrix = engine.matrices\n",
    "            if index == 0:\n",
    "                list_count_matrix = tmp_count_matrix\n",
    "                list_avg_matrix = tmp_avg_matrix\n",
    "            else:\n",
    "                list_count_matrix = np.concatenate((list_count_matrix, tmp_count_matrix))\n",
    "                list_avg_matrix = np.concatenate((list_avg_matrix, tmp_avg_matrix))\n",
    "        \n",
    "        count_total, matrix_total, result_total = hm.cpu_accumulate_and_return(list_count_matrix, list_avg_matrix)\n",
    "        \n",
    "        values.append(result_total)\n",
    "        count_matrix_2[(epsilon, samples, turn_sampling[i])] = count_total\n",
    "        average_matrix_2[(epsilon, samples, turn_sampling[i])] = matrix_total\n",
    "    \n",
    "    steps = [1]\n",
    "    while True:\n",
    "        if (values[0][0].shape[0] - 1) / steps[-1] > 4:\n",
    "            steps.append(steps[-1] * 2)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    for jump in steps:\n",
    "        for j in range(len(values[0])):\n",
    "            DA = []\n",
    "            error = []\n",
    "            DA_mc = []\n",
    "            raw_error_mc = []\n",
    "            error_mc = []\n",
    "            for i in range(len(turn_sampling)):\n",
    "                DA.append(np.power(integrate.romb(values[i][j][::jump], d_preliminar_alpha * jump) * 0.5, 1/4))\n",
    "                temp = np.power(integrate.romb(values[i][j][::jump * 2], d_preliminar_alpha * jump * 2) * 0.5, 1/4)\n",
    "                error.append(np.absolute(DA[-1] - temp))\n",
    "                \n",
    "                DA_mc.append(np.power(np.average(values[i][j][::jump]), 1/4))\n",
    "                raw_error_mc.append(np.std(values[i][j][::jump]))\n",
    "                error_mc.append(0.25 * np.power(DA_mc[-1], -3) * np.std(values[i][j][::jump]) / np.sqrt(np.size(values[i][j][::jump])))\n",
    "                \n",
    "            DA_2[(epsilon, len(values[i][j][::jump]), 2 ** (j), \"int\")] = DA\n",
    "            error_2[(epsilon, len(values[i][j][::jump]), 2 ** (j), \"int\")] = error\n",
    "            DA_2[(epsilon, len(values[i][j][::jump]), 2 ** (j), \"mc\")] = DA_mc\n",
    "            error_2[(epsilon, len(values[i][j][::jump]), 2 ** (j), \"mc\")] = error_mc\n",
    "            raw_error_2[(epsilon, len(values[i][j][::jump]), 2 ** (j), \"mc\")] = raw_error_mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/DA_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(DA_2, f, protocol=4)\n",
    "    \n",
    "with open(\"data/error_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(error_2, f, protocol=4)\n",
    "\n",
    "with open(\"data/raw_error_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(raw_error_2, f, protocol=4)    \n",
    "\n",
    "# with open(\"data/count_matrix_2.pkl\", 'wb') as f:\n",
    "#     pickle.dump(count_matrix_2, f, protocol=4)\n",
    "    \n",
    "# with open(\"data/avg_matrix_2.pkl\", 'wb') as f:\n",
    "#     pickle.dump(average_matrix_2, f, protocol=4)\n",
    "\n",
    "with open(\"data/DA_5.pkl\", 'wb') as f:\n",
    "    pickle.dump(DA_5, f, protocol=4)\n",
    "    \n",
    "with open(\"data/error_5.pkl\", 'wb') as f:\n",
    "    pickle.dump(error_5, f, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the end, we need to plot stuff here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "cmap = matplotlib.cm.get_cmap('plasma')\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "for key in tqdm(list(sorted(count_matrix_2, key=lambda a : a[2]))):\n",
    "    if key[0] == epsilon:\n",
    "        for i in tqdm(range(len(average_matrix_2[key]))):\n",
    "            fig, axs = plt.subplots(1,2, figsize=(12,6))\n",
    "\n",
    "            coso = axs[0].imshow(np.nanmean(average_matrix_2[key][i], axis=0), origin=\"lower\", extent=(0, np.pi*2, 0, np.pi*2))\n",
    "            axs[0].set_title(\"Average radius measured\\n$\\\\varepsilon={}$, $\\\\alpha$ samples $= {}$, $N$ iters $={}$\".format(key[0], key[1], key[2]))\n",
    "            axs[0].set_xlabel(\"$\\\\theta_1$\")\n",
    "            axs[0].set_ylabel(\"$\\\\theta_2$\")\n",
    "            fig.colorbar(coso, ax=axs[0])\n",
    "\n",
    "            axs[0].xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: str(int(x/np.pi)) + \"$\\\\pi$\"))\n",
    "            axs[0].xaxis.set_major_locator(ticker.MultipleLocator(base=np.pi))\n",
    "            axs[0].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: str(int(x/np.pi)) + \"$\\\\pi$\"))\n",
    "            axs[0].yaxis.set_major_locator(ticker.MultipleLocator(base=np.pi))\n",
    "\n",
    "            coso = axs[1].imshow(np.nanmean(count_matrix_2[key][i], axis=0), origin=\"lower\", extent=(0, np.pi*2, 0, np.pi*2))\n",
    "            axs[1].set_title(\"Number of samples\\n$\\\\varepsilon={}$, $\\\\alpha$ samples $= {}$, $N$ iters $={}$\".format(key[0], key[1], key[2]))\n",
    "            axs[1].set_xlabel(\"$\\\\theta_1$\")\n",
    "            axs[1].set_ylabel(\"$\\\\theta_2$\")\n",
    "            fig.colorbar(coso, ax=axs[1])\n",
    "\n",
    "            axs[1].xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: str(int(x/np.pi)) + \"$\\\\pi$\"))\n",
    "            axs[1].xaxis.set_major_locator(ticker.MultipleLocator(base=np.pi))\n",
    "            axs[1].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: str(int(x/np.pi)) + \"$\\\\pi$\"))\n",
    "            axs[1].yaxis.set_major_locator(ticker.MultipleLocator(base=np.pi))\n",
    "\n",
    "            plt.tight_layout()\n",
    "            # print(key)\n",
    "            plt.savefig(\"img/cm_eps_\" + str(int(key[0])) + \"_N_\" + str(key[1]) + \"_t_\" + str(key[2]) + \"_el_\" + str(i) + \".jpg\", dpi=300)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import ffmpeg\n",
    "\n",
    "#name = \"img/movie.mp4\"\n",
    "#(\n",
    "#    ffmpeg\n",
    "#    .input('img/cm_eps*el*.jpg', pattern_type='glob', framerate=2)\n",
    "#    .output(name)\n",
    "#    .run()\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
